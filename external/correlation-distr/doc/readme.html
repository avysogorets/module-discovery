<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="Docutils 0.5: http://docutils.sourceforge.net/" />
<title>Correlation Clustering</title>
<style type="text/css">

/*
:Author: David Goodger
:Contact: goodger@python.org
:Date: $Date: 2006-05-21 22:44:42 +0200 (Sun, 21 May 2006) $
:Revision: $Revision: 4564 $
:Copyright: This stylesheet has been placed in the public domain.

Default cascading style sheet for the HTML output of Docutils.

See http://docutils.sf.net/docs/howto/html-stylesheets.html for how to
customize this style sheet.
*/

/* used to remove borders from tables and images */
.borderless, table.borderless td, table.borderless th {
  border: 0 }

table.borderless td, table.borderless th {
  /* Override padding for "table.docutils td" with "! important".
     The right padding separates the table cells. */
  padding: 0 0.5em 0 0 ! important }

.first {
  /* Override more specific margin styles with "! important". */
  margin-top: 0 ! important }

.last, .with-subtitle {
  margin-bottom: 0 ! important }

.hidden {
  display: none }

a.toc-backref {
  text-decoration: none ;
  color: black }

blockquote.epigraph {
  margin: 2em 5em ; }

dl.docutils dd {
  margin-bottom: 0.5em }

/* Uncomment (and remove this text!) to get bold-faced definition list terms
dl.docutils dt {
  font-weight: bold }
*/

div.abstract {
  margin: 2em 5em }

div.abstract p.topic-title {
  font-weight: bold ;
  text-align: center }

div.admonition, div.attention, div.caution, div.danger, div.error,
div.hint, div.important, div.note, div.tip, div.warning {
  margin: 2em ;
  border: medium outset ;
  padding: 1em }

div.admonition p.admonition-title, div.hint p.admonition-title,
div.important p.admonition-title, div.note p.admonition-title,
div.tip p.admonition-title {
  font-weight: bold ;
  font-family: sans-serif }

div.attention p.admonition-title, div.caution p.admonition-title,
div.danger p.admonition-title, div.error p.admonition-title,
div.warning p.admonition-title {
  color: red ;
  font-weight: bold ;
  font-family: sans-serif }

/* Uncomment (and remove this text!) to get reduced vertical space in
   compound paragraphs.
div.compound .compound-first, div.compound .compound-middle {
  margin-bottom: 0.5em }

div.compound .compound-last, div.compound .compound-middle {
  margin-top: 0.5em }
*/

div.dedication {
  margin: 2em 5em ;
  text-align: center ;
  font-style: italic }

div.dedication p.topic-title {
  font-weight: bold ;
  font-style: normal }

div.figure {
  margin-left: 2em ;
  margin-right: 2em }

div.footer, div.header {
  clear: both;
  font-size: smaller }

div.line-block {
  display: block ;
  margin-top: 1em ;
  margin-bottom: 1em }

div.line-block div.line-block {
  margin-top: 0 ;
  margin-bottom: 0 ;
  margin-left: 1.5em }

div.sidebar {
  margin-left: 1em ;
  border: medium outset ;
  padding: 1em ;
  background-color: #ffffee ;
  width: 40% ;
  float: right ;
  clear: right }

div.sidebar p.rubric {
  font-family: sans-serif ;
  font-size: medium }

div.system-messages {
  margin: 5em }

div.system-messages h1 {
  color: red }

div.system-message {
  border: medium outset ;
  padding: 1em }

div.system-message p.system-message-title {
  color: red ;
  font-weight: bold }

div.topic {
  margin: 2em }

h1.section-subtitle, h2.section-subtitle, h3.section-subtitle,
h4.section-subtitle, h5.section-subtitle, h6.section-subtitle {
  margin-top: 0.4em }

h1.title {
  text-align: center }

h2.subtitle {
  text-align: center }

hr.docutils {
  width: 75% }

img.align-left {
  clear: left }

img.align-right {
  clear: right }

ol.simple, ul.simple {
  margin-bottom: 1em }

ol.arabic {
  list-style: decimal }

ol.loweralpha {
  list-style: lower-alpha }

ol.upperalpha {
  list-style: upper-alpha }

ol.lowerroman {
  list-style: lower-roman }

ol.upperroman {
  list-style: upper-roman }

p.attribution {
  text-align: right ;
  margin-left: 50% }

p.caption {
  font-style: italic }

p.credits {
  font-style: italic ;
  font-size: smaller }

p.label {
  white-space: nowrap }

p.rubric {
  font-weight: bold ;
  font-size: larger ;
  color: maroon ;
  text-align: center }

p.sidebar-title {
  font-family: sans-serif ;
  font-weight: bold ;
  font-size: larger }

p.sidebar-subtitle {
  font-family: sans-serif ;
  font-weight: bold }

p.topic-title {
  font-weight: bold }

pre.address {
  margin-bottom: 0 ;
  margin-top: 0 ;
  font-family: serif ;
  font-size: 100% }

pre.literal-block, pre.doctest-block {
  margin-left: 2em ;
  margin-right: 2em }

span.classifier {
  font-family: sans-serif ;
  font-style: oblique }

span.classifier-delimiter {
  font-family: sans-serif ;
  font-weight: bold }

span.interpreted {
  font-family: sans-serif }

span.option {
  white-space: nowrap }

span.pre {
  white-space: pre }

span.problematic {
  color: red }

span.section-subtitle {
  /* font-size relative to parent (h1..h6 element) */
  font-size: 80% }

table.citation {
  border-left: solid 1px gray;
  margin-left: 1px }

table.docinfo {
  margin: 2em 4em }

table.docutils {
  margin-top: 0.5em ;
  margin-bottom: 0.5em }

table.footnote {
  border-left: solid 1px black;
  margin-left: 1px }

table.docutils td, table.docutils th,
table.docinfo td, table.docinfo th {
  padding-left: 0.5em ;
  padding-right: 0.5em ;
  vertical-align: top }

table.docutils th.field-name, table.docinfo th.docinfo-name {
  font-weight: bold ;
  text-align: left ;
  white-space: nowrap ;
  padding-left: 0 }

h1 tt.docutils, h2 tt.docutils, h3 tt.docutils,
h4 tt.docutils, h5 tt.docutils, h6 tt.docutils {
  font-size: 100% }

ul.auto-toc {
  list-style-type: none }

</style>
</head>
<body>
<div class="document" id="correlation-clustering">
<h1 class="title">Correlation Clustering</h1>

<!-- To convert this document to HTML, use command line tool rst2html. -->
<div class="contents topic">
<p class="topic-title first"><a id="contents" name="contents">Contents</a></p>
<ul class="simple">
<li><a class="reference" href="#setup" id="id12" name="id12">Setup</a><ul>
<li><a class="reference" href="#license" id="id13" name="id13">License</a></li>
<li><a class="reference" href="#downloading-and-compiling" id="id14" name="id14">Downloading and compiling</a></li>
<li><a class="reference" href="#external-software" id="id15" name="id15">External Software</a></li>
</ul>
</li>
<li><a class="reference" href="#notes" id="id16" name="id16">Notes</a></li>
<li><a class="reference" href="#making-data" id="id17" name="id17">Making data</a><ul>
<li><a class="reference" href="#making-artificial-points" id="id18" name="id18">Making Artificial Points</a></li>
<li><a class="reference" href="#making-artificial-weight-matrices" id="id19" name="id19">Making Artificial Weight Matrices</a></li>
<li><a class="reference" href="#making-the-twenty-newsgroups-weight-matrices" id="id20" name="id20">Making the Twenty Newsgroups Weight Matrices</a></li>
<li><a class="reference" href="#making-the-chat-weight-matrices" id="id21" name="id21">Making the Chat Weight Matrices</a></li>
<li><a class="reference" href="#viewing-weight-matrices" id="id22" name="id22">Viewing Weight Matrices</a></li>
</ul>
</li>
<li><a class="reference" href="#finding-clusterings" id="id23" name="id23">Finding Clusterings</a><ul>
<li><a class="reference" href="#building" id="id24" name="id24">Building</a></li>
<li><a class="reference" href="#using-our-recommended-solver" id="id25" name="id25">Using Our Recommended Solver</a></li>
<li><a class="reference" href="#chained-solvers" id="id26" name="id26">Chained Solvers</a></li>
</ul>
</li>
<li><a class="reference" href="#evaluation" id="id27" name="id27">Evaluation</a><ul>
<li><a class="reference" href="#references" id="id28" name="id28">References</a></li>
</ul>
</li>
</ul>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id12" id="setup" name="setup">Setup</a></h1>
<p>This is the software for <a class="citation-reference" href="#elsnerschudy09" id="id1" name="id1">[ElsnerSchudy09]</a>. It contains software for
creating, analyzing and solving correlation clustering problems.</p>
<div class="section">
<h2><a class="toc-backref" href="#id13" id="license" name="license">License</a></h2>
<p>Our code is available under the terms of the GPL version 2.0 or later. In addition, as a special exception, we also give permission to link our code with linear programming and semi-definite programming solvers regardless of the licenses of such solvers. When exercising your distribution rights under the GPL you need not include the source code for such solvers. Note that people who make modified versions of our code are not obligated to grant this special exception for their modified versions; it is their choice whether to do so. The GPL gives permission to release a modified version without this exception; this exception also makes it possible to release a modified version which carries forward this exception.</p>
<p>Before distributing binaries please ensure that you do not violate the licenses of any LP or SDP solvers that you link against; two examples follow. The CPLEX license presumably does not allow distribution of binaries containing CPLEX. The ConicBundle is licensed under the GPL without the above exception, therefore only distribute binaries containing ConicBundle if all solvers linked with are GPL compatible.</p>
<p>We are not lawyers and this is not legal advice.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id14" id="downloading-and-compiling" name="downloading-and-compiling">Downloading and compiling</a></h2>
<p>First download the clustering.tgz tarball from <em>cs.brown.edu/~melsner</em>
and &quot;tar xzf&quot; it, yielding the <em>correlation</em> directory.</p>
<p>The executable that actually does the clustering, <em>chainedSolvers</em>, is
written in C++. See the C++ building section of this manual for
building instructions, or pray and then run the following:</p>
<pre class="literal-block">
cd correlation
mkdir bin32
mkdir lib32
make chainedSolvers
</pre>
<p>Our support code that does everything else, such as evaluating a
clustering, generating artificial data, and visualization, is written
in Python. Please set your python path to include all necessary
packages (notably the waterworks utility library and pylab). Also edit
the script <em>script/megam.py</em> to point to the correct <em>megam</em> binary.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id15" id="external-software" name="external-software">External Software</a></h2>
<p>Some features of this software require external packages. You can do
without most of these packages if you are willing to forgo various
features of the software:</p>
<blockquote>
<p><a class="citation-reference" href="#waterworks" id="id2" name="id2">[waterworks]</a> : David McClosky and others (python utility package,
including ClusterMetrics library for evaluating clusterings)</p>
<p>pylab plotting library, which in turn needs <a class="citation-reference" href="#matplotlib" id="id3" name="id3">[matplotlib]</a> (plotting)</p>
<p><a class="citation-reference" href="#megam" id="id4" name="id4">[megam]</a> : Hal Daume III (max-ent classifier)</p>
<p>python package for disentangling <a class="citation-reference" href="#chat" id="id5" name="id5">[chat]</a> : Micha Elsner</p>
<p><a class="citation-reference" href="#cplex" id="id6" name="id6">[CPLEX]</a> : ILOG Inc. (solves LP and ILP problems)</p>
<p><a class="citation-reference" href="#dsdp" id="id7" name="id7">[DSDP]</a> : Benson, Ye and Zhang (solves SDPs)</p>
<p><a class="citation-reference" href="#conicbundle" id="id8" name="id8">[ConicBundle]</a> : Christoph Helmberg (solves SDPs) We used version
0.2i of Conic Bundle.</p>
</blockquote>
</div>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id16" id="notes" name="notes">Notes</a></h1>
<p>Program descriptions below only show the most useful features. To
get a usage message, try running the program without arguments, or with the
flag <em>-h</em>.</p>
<p>In general (but not always, thanks CPLEX!), programs write the
output of their computation to stdout and everything else (debugging
notes, iteration tickers, bonus information) to stderr. Most of the
time you will want to use the output redirect <em>&gt;</em>.</p>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id17" id="making-data" name="making-data">Making data</a></h1>
<div class="section">
<h2><a class="toc-backref" href="#id18" id="making-artificial-points" name="making-artificial-points">Making Artificial Points</a></h2>
<p>A dataset is essentially a vector of points and their cluster
labels, in the format:</p>
<pre class="literal-block">
[label] [feat val]*
</pre>
<p><em>label</em> determines the cluster to which the point belongs, and is a
positive integer. <em>feat</em> can be any string, and <em>val</em> is a real
number.</p>
<p>Each datafile usually contains two sections, one for training and one
for testing, separated by a newline.</p>
<p>There are two primary ways to make artificial datasets: featureless data
(just cluster labels) and Gaussian data (points drawn from spherical
clusters). Both methods pick the number of clusters and cluster sizes
stochastically (some parameters of the distributions are controlled by
command line arguments).</p>
<p>To get featureless points, use:</p>
<pre class="literal-block">
python script/genFeatureless.py -n [number of points]
</pre>
<p>The generative model for featureless points is:</p>
<pre class="literal-block">
n (number of points) ~ command line
k (number of clusters) ~ command line | log_1.5(n)
alpha (prior parameter) ~ command line | 1
p (k-dimensional vector of cluster probabilities) ~ Dirichlet(alpha) | uniform if command line parameter &quot;balanced&quot;
z (number of points in each cluster) ~ Multinomial(p, n)
</pre>
<p>To get Gaussian points, use:</p>
<pre class="literal-block">
python script/genGaussians.py -n [number of points] -t [number of training points] -f [number of features]
</pre>
<p>The generative model for Gaussian points is:</p>
<pre class="literal-block">
z (number of points in each cluster) ~ same as featureless
f (number of features) ~ command line | 1
vv (optional parameter controlling feature variances) ~ command line
sigma (k*f matrix of variances of each cluster) ~ command line | InverseGamma(vv, 1)
mu (k*f matrix of means of each cluster) ~ Gaussian(0, sigma)
F[i,j] (feature j of point i in cluster k_i) ~ Gaussian(mu[k_i,j], sigma[k_i,j])
</pre>
<p>To make a clustering with all clusters of size 1, use</p>
<pre class="literal-block">
python script/genSingletons.py -n [number of points]
</pre>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id19" id="making-artificial-weight-matrices" name="making-artificial-weight-matrices">Making Artificial Weight Matrices</a></h2>
<p>To make a weight matrix, you first need to generate the points as described in the previous section. Then you need to run a classifier.</p>
<p>We provide three classifiers for general experimentation. To find the
names of the classifiers to use as <em>-c</em> arguments, run the script with
<em>-a</em>; it will print a list.</p>
<p>Our first classifier makes random errors. This is sometimes a useful
algorithmic model (and has been studied theoretically: see the
paper). This is also the only classifier which does anything useful
with featureless synthetic points. You can set the parameters
<em>epsilon</em>, <em>A</em> and <em>B</em> via command line options (the flag
<em>--simple</em> creates a 0-1 instance where <em>A</em> and <em>B</em> are ignored).</p>
<table border="1" class="docutils">
<colgroup>
<col width="35%" />
<col width="41%" />
<col width="24%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">True state</th>
<th class="head" colspan="2">Classifier decision</th>
</tr>
</thead>
<tbody valign="top">
<tr><td rowspan="2">Same cluster</td>
<td>with p(1 - epsilon)</td>
<td>Beta(A,B)</td>
</tr>
<tr><td>with p(epsilon)</td>
<td>Beta(B,A)</td>
</tr>
<tr><td rowspan="2">Diff cluster</td>
<td>with p(1 - epsilon)</td>
<td>Beta(B,A)</td>
</tr>
<tr><td>with p(epsilon)</td>
<td>Beta(A,B)</td>
</tr>
</tbody>
</table>
<p>The other two classifiers actually learn models from the data, and
require points with features. The first (Naive Bayes) assumes all features are
independent samples from Gaussians, and learns Gaussian distributions
on the differences of features for within-class and cross-class
instances. The second (Max Ent) learns a logistic regression on
feature differences instead.</p>
<pre class="literal-block">
python script/classify.py -c [classifier] [data file]
</pre>
<p>The stderr stream output will look like this:</p>
<pre class="literal-block">
test classifier performance
P: 85.71 R: 100.00 F: 92.31 Acc: 90 (9/10)
</pre>
<p>Here P is precision of <em>same cluster</em> class (number of correct <em>same
cluster</em> decisions / number of <em>same cluster</em> decisions), R is recall
(number of correct <em>same cluster</em> decisions / number of true <em>same
cluster</em> edges), F is F-score (geometric mean of P and R), Acc is
accuracy (number correct / number of edges). In particular, watch out
for values like F = 0, Acc = .9: this means that the classifier is
useless-- it will always say <em>different cluster</em>, but since that's
usually the correct decision, accuracy is misleadingly high.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id20" id="making-the-twenty-newsgroups-weight-matrices" name="making-the-twenty-newsgroups-weight-matrices">Making the Twenty Newsgroups Weight Matrices</a></h2>
<p>The best way to get the newsgroup weight matrices we used is directly
off the web, at <em>cs.brown.edu/~melsner</em>. We are providing our
newsgroup processing code in order to make our work replicable, not
because it is particularly general, elegant or effective.</p>
<p>If you are insistent on actually running the newsgroup code, first you
have to actually get the <a class="citation-reference" href="#mini-newsgroups" id="id9" name="id9">[mini_newsgroups]</a> dataset from the UCI
machine learning repository.</p>
<p>Next, edit <em>script/newsgroup.py</em>, setting the path to your newsgroup
directory and a filename for the term frequency dump file which the
script will create. Run the script:</p>
<pre class="literal-block">
python script/newsgroup.py
</pre>
<p>Now edit <em>script/newsgroupToDataset.py</em> and set the same path to the
dump file. Also set a path to an empty directory where the program
will dump the data files. This program will transform the newsgroup
data into data files with integer cluster labels and term/count
features, and create five training/testing splits of the data.</p>
<pre class="literal-block">
python script/newsgroup.py
</pre>
<p>Now comes the really ugly part; we did the Latent Semantic Analysis decomposition by hand, in Matlab. There are plenty of ways to reimplement this using any linear algebra package, though.</p>
<p>Here's what we did: use <em>script/writeSparseMat.py</em> to write each data
matrix into a Matlab sparse matrix file. Now use Matlab to import the
file. Run the following Matlab commands:</p>
<pre class="literal-block">
[u, s, v] = svds(mat, 200)
save '&lt;lsa-filename&gt;' -ascii u
</pre>
<p>Now add these features back to the original dataset using:</p>
<pre class="literal-block">
python script/lsa.py [original dataset] [lsa-filename] &gt; [augmented file]
</pre>
<p>Finally, you can run the newsgroup classifier:</p>
<pre class="literal-block">
python script/classify.py -c mxnews [lsa-augmented file]
</pre>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id21" id="making-the-chat-weight-matrices" name="making-the-chat-weight-matrices">Making the Chat Weight Matrices</a></h2>
<p>Make sure you have a copy of the chat disentanglement package
(<a class="citation-reference" href="#chat" id="id10" name="id10">[chat]</a>). Follow the instructions to create a set of predictions for
your dataset (eg, using <em>classifierTest</em>). Now use:</p>
<pre class="literal-block">
python script/correlationClusteringData.py [chat file] [predictions file] [keys file] [output true labels] [output weight matrix]
</pre>
<p>Note that the &quot;true labels&quot; file will contain a fake training section
with a single point.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id22" id="viewing-weight-matrices" name="viewing-weight-matrices">Viewing Weight Matrices</a></h2>
<p>To view a weight matrix such as one output by classify.py, use</p>
<pre class="literal-block">
python script/colorMat.py [matrix file]
</pre>
<p>The matrix is color-coded. Red indicates 1, i.e. the classifier
believes the points belong in the same cluster with 100 percent
probability. Blue indicates 0, i.e. the points definitely belong in
different clusters.</p>
<p>This utility can also be used to view the output of the &quot;print&quot;
command in chainedSolvers.</p>
<p>You can also view the weight matrix and a clustering solution all at
once, by running:</p>
<pre class="literal-block">
python script/colorMatAndTruth.py [matrix file] [solution file]
</pre>
<p>The solution file can be the original datafile from which the weight
matrix was produced, or the clustering provided by one of our
solvers. The display puts the weights in the upper triangle of the
matrix, and the solution in the lower triangle.</p>
</div>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id23" id="finding-clusterings" name="finding-clusterings">Finding Clusterings</a></h1>
<div class="section">
<h2><a class="toc-backref" href="#id24" id="building" name="building">Building</a></h2>
<p>Our Makefile has been tested on our x86 Debian GNU/Linux systems
only. Use on other platforms may require changes to the Makefile. The
Makefile automatically identifies whether the machine compiled on is
32 or 64 bit.</p>
<p>Our code supports two SDP solvers, DSDP and Conic Bundle, and one LP
solver, CPLEX. Without those solvers our code will still compile and
run, but LP and SDP based lower bounds will not be available. If you
have installed one or more of these solvers and wish to use them, set
the appropriate directories as documented in the Makefile.</p>
<p>Before building create a <em>bin32</em> directory and a <em>lib32</em> directory (or
64-bit equivalents). For convenience, it's nice to symlink <em>bin</em> to
<em>bin32</em>.</p>
<p>To make a binary such as chainedSolvers, go to the main directory and
&quot;make chainedSolvers&quot;. The binary will be placed in the bin32 or bin64
directory as appropriate.</p>
<p>All these tools basically take a matrix file as input and write a
vector of cluster indices to stdout.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id25" id="using-our-recommended-solver" name="using-our-recommended-solver">Using Our Recommended Solver</a></h2>
<p>You can run the heuristic we recommend in the paper in the following way:</p>
<pre class="literal-block">
bin/chainedSolvers log vote boem [matrix] &gt; [solution]
</pre>
<p>In our experiments, we do this 100 times, check the objective values,
and take the best (lowest) objective.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id26" id="chained-solvers" name="chained-solvers">Chained Solvers</a></h2>
<p>You can run a long sequence of solvers (for instance, to solve an SDP
and then round the solution to integrality) using the <em>chainedSolvers</em>
program. Most of the solvers treat the output of the previous solver
as if it were the input matrix. The local search solvers BOEM and
simulated annealing act differently, treating the output of the
previous solver as an initial clustering to improve. The local search
solvers use one huge cluster as the initial clustering if run as the
first solver.</p>
<pre class="literal-block">
bin/chainedSolvers [solver_1..solver_n] [matrix]
</pre>
<p>To preprocess the edge weights by taking logarithms, add &quot;log&quot; as the
first argument to chainedSolvers. (Actually you can hide &quot;log&quot; in the
middle of the solver list if you want to accomplish the same thing
with extra confusion.)</p>
<p>For instance, to run SDP, round with voting, and
improve the solution with best one-element, use:</p>
<pre class="literal-block">
bin/chainedSolvers log sdp2 vote boem [matrix]
</pre>
<p>There are three additional special &quot;solvers&quot;. The &quot;stats&quot; solver
prints information about the current solution and input. The &quot;print&quot;
solver prints the current solution to a file in the current directory
suitable for viewing with the colorMat.py script. It is often useful
to put &quot;print&quot; in the middle of a list of solver, e.g. to output the
SDP solution before rounding. The &quot;read&quot; solver restores the state as
of the last &quot;print&quot; solver. This is useful for reusing the painfully
slow SDP solutions. For example, first run:</p>
<pre class="literal-block">
bin/chainedSolvers log sdp2 print [matrix]
</pre>
<p>to write the SDP solution to a file, currently hard-coded to &quot;clustering.mat&quot;. Then round it, e.g.</p>
<pre class="literal-block">
bin/chainedSolvers log read vote boem [matrix]
</pre>
<p>For a net result equivalent to:</p>
<pre class="literal-block">
bin/chainedSolvers log sdp2 vote boem [matrix]
</pre>
<p>The advantage of using read and print is you can use the same SDP
solution multiple times.</p>
<p>To get a full list of solver names the program will accept, or tweak
construction arguments to any of the solvers, you'll need to edit the code.</p>
</div>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id27" id="evaluation" name="evaluation">Evaluation</a></h1>
<p>The chainedSolvers application automatically prints objective function
values after each solution step for ease of debugging. To evaluate a
solution against the ground truth, run:</p>
<pre class="literal-block">
python script/evaluate.py [data] [matrix] [output_1 .. output_n]
</pre>
<p>(The output files should be vectors of node indices. Make sure these
files don't contain log statements from CPLEX or something.)</p>
<p>The output will look something like this:</p>
<pre class="literal-block">
True clustering has 2 clusters
Objective value of truth: 2.44759404055
Best Rand:
File: data/featureless1/gpivot6
Clusters: 2
Objective: 2.45
Objective (log): -18

Some edge-counting metrics:
Rand index (max 1): 1
Jaccard index (max 1): 1
Mirkin metric (min 0): 0
(Same cluster) Prec: 1 Rec: 1 F: 1

Some node-counting metrics:
One-to-one match (max 1): 1
Many-to-one match (max 1): 1
Variation of information (min 0, max 2.32): 0
Normalized mutual information (0-1): 1
</pre>
<p>For definitions of the metrics used, see the pydoc for the
ClusterMetrics package. Most of the metrics are defined in <a class="citation-reference" href="#meila99" id="id11" name="id11">[Meila99]</a>.</p>
<div class="section">
<h2><a class="toc-backref" href="#id28" id="references" name="references">References</a></h2>
<table class="docutils citation" frame="void" id="elsnerschudy09" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1" name="elsnerschudy09">[ElsnerSchudy09]</a></td><td>Micha Elsner and Warren Schudy. &quot;Bounding and Comparing Methods for Correlation Clustering Beyond ILP&quot;. ILP-NLP '09.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="waterworks" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2" name="waterworks">[waterworks]</a></td><td><a class="reference" href="http://www.cs.brown.edu/~dmcc/software/waterworks/">http://www.cs.brown.edu/~dmcc/software/waterworks/</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="mini-newsgroups" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id9" name="mini-newsgroups">[mini_newsgroups]</a></td><td><a class="reference" href="http://archive.ics.uci.edu/ml/databases/20newsgroups/20newsgroups.html">http://archive.ics.uci.edu/ml/databases/20newsgroups/20newsgroups.html</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="meila99" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id11" name="meila99">[Meila99]</a></td><td>Marina Meila. &quot;Comparing Clusterings&quot;. UW Statistics Technical Reports, COLT '03. <a class="reference" href="http://www.stat.washington.edu/mmp/www.stat.washington.edu/mmp/Papers/compare-colt.pdf">http://www.stat.washington.edu/mmp/www.stat.washington.edu/mmp/Papers/compare-colt.pdf</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="megam" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id4" name="megam">[megam]</a></td><td>Hal Daume III. Paper at <a class="reference" href="http://pub.hal3.name#daume04cfg-bfgs.pdf">http://pub.hal3.name#daume04cfg-bfgs.pdf</a>, program at <a class="reference" href="http://hal3.name/megam">http://hal3.name/megam</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="matplotlib" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id3" name="matplotlib">[matplotlib]</a></td><td><a class="reference" href="http://matplotlib.sourceforge.net/">http://matplotlib.sourceforge.net/</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="chat" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a name="chat">[chat]</a></td><td><em>(<a class="fn-backref" href="#id5">1</a>, <a class="fn-backref" href="#id10">2</a>)</em> Paper: Micha Elsner and Eugene Charniak. &quot;You Talking To Me? A Corpus and Algorithm for Conversation Disentanglement&quot;. ACL '08. Software: <a class="reference" href="http://cs.brown.edu/~melsner/chat-distr.tgz">http://cs.brown.edu/~melsner/chat-distr.tgz</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="cplex" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id6" name="cplex">[CPLEX]</a></td><td><a class="reference" href="http://www.ilog.com/products/cplex/">http://www.ilog.com/products/cplex/</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="dsdp" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id7" name="dsdp">[DSDP]</a></td><td>Steven J. Benson, Yinyu Ye and Xiong Zhang. &quot;DSDP5: Software For Semidefinite Programming&quot;. Tech report, 2005. Software: <a class="reference" href="http://www.mcs.anl.gov/hs/software/DSDP/">http://www.mcs.anl.gov/hs/software/DSDP/</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="conicbundle" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id8" name="conicbundle">[ConicBundle]</a></td><td>Christoph Helmberg. &quot;Semidefinite programming for combinatorial optimization&quot;. Tech report, 2000. <a class="reference" href="http://www-user.tu-chemnitz.de/~helmberg/">http://www-user.tu-chemnitz.de/~helmberg/</a></td></tr>
</tbody>
</table>
</div>
</div>
</div>
</body>
</html>
